# training parameters
lr: 0.0001
weight_decay: 0.0001
# optimizer: Adam
aeWarmEpochs: 1

# training scheduler
lr_scheduler: 'step'
lr_decay_steps: 80
lr_decay_rate: 0.5
lr_decay_min_lr: 0.00001
updtR_epoches: 15

# model parameters
# input_shape: [3, 8, 32, 32]
code_length: 64
nu: 0.01
objFlg: 'soft'

# loss parameters
oneLsAlpha: 1 #1-0.827, 2-0.839 #5-0.826
aeLsAlpha: 20
gdLsAlpha: 1 #1
tgLsAlpha: 10 #20 # 20-0.839, 50-0.81ï¼Œ10-0.830
cntNum: 1 # clusters

tgScoreAlpha: [0.5, 0, 1, 3, 5, 8, 10]
aeScoreAlpha: [1, 2, 5, 8, 10]
#gdScoreAlpha: [0.5, 1, 2, 5, 8]
oneScoreAlpha: [-2, -1, -0.5, -0.1, 0, 0.1, 0.5, 1, 2, 5]

