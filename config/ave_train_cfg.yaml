# training parameters
lr: 0.0001
weight_decay: 0.0001
# optimizer: Adam
aeWarmEpochs: 1

# training scheduler
lr_scheduler: 'step'
lr_decay_steps: 80
lr_decay_rate: 0.8
lr_decay_min_lr: 0.00001
updtR_epoches: 15

# model parameters
# input_shape: [3, 8, 32, 32]
code_length: 64
nu: 0.01

# loss parameters
oneLsAlpha: 2 #1-0.827, 2-0.839 #5-0.826
aeLsAlpha: 1
gdLsAlpha: 1 #1
tgLsAlpha: 20 #20 # 20-0.839, 50-0.81ï¼Œ10-0.830
cntNum: 1 # clusters

tgScoreAlpha: [0.5, 1, 3, 5, 8]
aeScoreAlpha: [0.5, 1, 2, 5, 8]
gdScoreAlpha: [0.5, 1, 2, 5, 8]
oneScoreAlpha: [0.1, 0.5, 1, 2, 5]

